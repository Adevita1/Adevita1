{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCpYC3RvlK1z8DOADO/Hqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adevita1/Adevita1/blob/main/TEXTEXTRACTOR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instalar todas las librerias:\n",
        "# pip install beautifulsoup4\n",
        "# pip install requests\n",
        "# pip install spacy\n",
        "# pip intall textblob\n",
        "# pip install transformers\n",
        "# https://www.youtube.com/watch?v=kPNHKrOqedI\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from transformers import pipeline\n",
        "\n",
        "# URL del sitio para hacer WebScraping\n",
        "website = 'https://www.theguardian.com/books/2022/nov/05/i-want-to-open-a-window-in-their-souls-haruki-murakami-on-the-power-of-writing-simply'\n",
        "\n",
        "\n",
        "# Realizar la solicitud web\n",
        "response = requests.get(website)\n",
        "content = response.text\n",
        "\n",
        "# Analizar el contenido HTML\n",
        "soup = BeautifulSoup(content, 'lxml')\n",
        "\n",
        "# Imprimir el HTML formateado\n",
        "print(soup.prettify())\n",
        "\n",
        "box = soup.find('article', class_='//*[@id=\"maincontent\"]/article')\n",
        "\n",
        "tittle = box.find('//*[@id=\"maincontent\"]/article/div/div/div[3]/div/div/h1').get_text(strip=True, separator=' ')\n",
        "transcript = box.find('//*[@id=\"maincontent\"]/article/div')\n",
        "\n",
        "print(tittle)\n",
        "print(transcript)\n",
        "\n",
        "\n",
        "\n",
        "# Cargar el modelo de extracción de entidades nombradas\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
        "\n",
        "# Analizar el sentimiento del artículo\n",
        "def analyze_sentiment(text):\n",
        "    blob = TextBlob(text)\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    if sentiment_score > 0:\n",
        "        return \"positivo\"\n",
        "    elif sentiment_score < 0:\n",
        "        return \"negativo\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "# Realizar el análisis de NLP para identificar frases significativas\n",
        "def analyze_nlp(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    meaningful_sentences = [sent.text for sent in doc.sents if len(sent.text) > 20]\n",
        "    return meaningful_sentences\n",
        "\n",
        "# Generar preguntas basadas en frases y sentimiento\n",
        "def generate_questions(sentences, sentiment):\n",
        "    questions = []\n",
        "    for sentence in sentences:\n",
        "        question = f\"¿Cómo afecta el análisis de NLP en esta frase '{sentence}' al proceso general? (Sentimiento: {sentiment})\"\n",
        "        questions.append(question)\n",
        "    return questions\n",
        "\n",
        "# Realizar la extracción de entidades nombradas y observaciones\n",
        "def extract_entities_and_observe(text):\n",
        "    entities = ner_pipeline(text)\n",
        "\n",
        "    print(\"Entidades nombradas identificadas:\")\n",
        "    for entity in entities:\n",
        "        print(f\"Entidad: {entity['word']}, Tipo: {entity['entity']}\")\n",
        "\n",
        "    num_entities = len(entities)\n",
        "    print(f\"Total de entidades identificadas: {num_entities}\")\n",
        "\n",
        "    entity_types = {}\n",
        "    for entity in entities:\n",
        "        entity_type = entity['entity']\n",
        "        if entity_type in entity_types:\n",
        "            entity_types[entity_type] += 1\n",
        "        else:\n",
        "            entity_types[entity_type] = 1\n",
        "\n",
        "    print(\"Conteo de entidades por tipo:\")\n",
        "    for entity_type, count in entity_types.items():\n",
        "        print(f\"{entity_type}: {count}\")\n",
        "\n",
        "    print(\"Entidades con longitudes inusuales:\")\n",
        "    for entity in entities:\n",
        "        word = entity['word']\n",
        "        if len(word) <= 2 or len(word) >= 15:\n",
        "            print(f\"Entidad: {word}, Tipo: {entity['entity']}\")\n",
        "\n",
        "    print(\"Entidades repetidas:\")\n",
        "    seen_entities = set()\n",
        "    for entity in entities:\n",
        "        word = entity['word']\n",
        "        if word in seen_entities:\n",
        "            print(f\"Entidad repetida: {word}, Tipo: {entity['entity']}\")\n",
        "        else:\n",
        "            seen_entities.add(word)\n",
        "\n",
        "# Texto completo del artículo (aquí va el artículo)\n",
        "\n",
        "# Analizar sentimiento\n",
        "sentiment = analyze_sentiment(article)\n",
        "print(f\"Sentimiento del artículo: {sentiment}\")\n",
        "\n",
        "# Analizar NLP\n",
        "meaningful_sentences = analyze_nlp(article)\n",
        "print(\"Frases significativas:\")\n",
        "for sentence in meaningful_sentences:\n",
        "    print(sentence)\n",
        "\n",
        "# Generar preguntas\n",
        "questions = generate_questions(meaningful_sentences, sentiment)\n",
        "print(\"Preguntas generadas:\")\n",
        "for question in questions:\n",
        "    print(question)\n",
        "\n",
        "# Realizar la extracción de entidades nombradas y observaciones\n",
        "extract_entities_and_observe(article)\n",
        "\n",
        "# Texto que analizamos: https://www.theguardian.com/books/2022/nov/05/i-want-to-open-a-window-in-their-souls-haruki-murakami-on-the-power-of-writing-simply"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "C0txufH8sdQ4",
        "outputId": "3a9ba657-ba5a-43ba-a8ff-467bec54f477"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1115afb34271>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# URL del sitio para hacer WebScraping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0qRQ4lFqNk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nIX0ZE0pqPAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}